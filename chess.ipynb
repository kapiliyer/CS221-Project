{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import chess\n",
    "\n",
    "PATH = 'data/chessData.csv'\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH, encoding=\"utf-8\")\n",
    "# 100k datapoints. White's turn. Preprocess to remove \"mate in X\" evaluations with '#' character. All values between -2k and 2k centipawns. No 0-evaluation.\n",
    "df['Evaluation'] = df['Evaluation'].apply(pd.to_numeric, errors='coerce')\n",
    "df = df[(-2000 <= df['Evaluation']) & (df['Evaluation'] <= 2000) & (df['Evaluation'] != 0) & (df['FEN'].apply(lambda fen: fen.split()[1]) == 'w')].dropna()[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2743de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Evaluation']\n",
    "fig = y.plot.hist(bins=100)\n",
    "fig.set_title('Distribution of Evaluation Scores over Dataset')\n",
    "fig.set_xlabel('Evaluation Score (Centipawns)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa70702",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 80/10/10 train/val/test split\n",
    "df_train, df_test  = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_val, df_test= train_test_split(df_test, test_size=0.5, random_state=1)\n",
    "print('Train/Validation/Test Splits: ' , df_train.shape[0], df_val.shape[0], df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Credits to @shailesh for portions of this code.\n",
    "https://github.com/ShaileshSridhar2403/neuralStockfish\n",
    "\"\"\"\n",
    "pieces = (chess.PAWN,chess.KNIGHT,chess.BISHOP,chess.ROOK,chess.QUEEN,chess.KING)\n",
    "colours = (chess.WHITE,chess.BLACK)\n",
    "\n",
    "def fenToVec(fen):\n",
    "\t\"\"\"\n",
    "\tInput: \n",
    "\tFEN string.\n",
    "\t\n",
    "\tOutput: 768-vector. Each of the 12 sets (where each set is one of the unique pieces) \n",
    "\tof 64 elements (where each element is a square) is a one-hot encoding of whether the\n",
    "\tpiece is on the square. 12 * 64 = 768.\n",
    "\t\"\"\"\n",
    "\tposFen = fen.split()[0]\n",
    "\tboard = chess.BaseBoard(posFen)\n",
    "\tl = []\n",
    "\t\n",
    "\tfor colour in colours:\n",
    "\t\tfor piece in pieces:\n",
    "\t\t\tv = np.zeros(64)\n",
    "\t\t\tfor i in board.pieces(piece,colour):\n",
    "\t\t\t\tv[i] = 1\n",
    "\t\t\tl.append(v)\n",
    "\tl = np.concatenate(l)\n",
    "\treturn l\n",
    "\n",
    "\n",
    "def vecToFen(vec):\n",
    "\t\"\"\"\n",
    "\tReverses above function.\n",
    "\t\"\"\"\n",
    "\tvecList = np.split(vec,12)\n",
    "\twhiteList = vecList[:6]\n",
    "\tblackList = vecList[6:]\n",
    "\tboard = chess.BaseBoard()\n",
    "\tboard.clear_board()\n",
    "\tfor pieceType in range(len(whiteList)):\n",
    "\t\tpieceArr = whiteList[pieceType]\n",
    "\t\tfor ind in range(len(pieceArr)):\n",
    "\t\t\tif pieceArr[ind]:\n",
    "\t\t\t\tboard.set_piece_at(ind ,chess.Piece(pieces[pieceType],chess.WHITE))\n",
    "\t\t\t\t\n",
    "\tfor pieceType in range(len(blackList)):\n",
    "\t\tpieceArr = blackList[pieceType]\n",
    "\t\tfor ind in range(len(pieceArr)):\n",
    "\t\t\tif pieceArr[ind]:\n",
    "\t\t\t\tboard.set_piece_at(ind ,chess.Piece(pieces[pieceType],chess.BLACK))\n",
    "\t\n",
    "\treturn board.board_fen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fenToVec2D(x):\n",
    "    return pd.DataFrame(x.apply(fenToVec).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel:\n",
    "    def __init__(self):\n",
    "        # Value of pieces in centipawns.\n",
    "        self.values = {chess.PAWN:100, chess.KNIGHT:300, chess.BISHOP:300, chess.ROOK:500, chess.QUEEN:900, chess.KING:0}\n",
    "\n",
    "    def predict(self, x):\n",
    "        board = chess.BaseBoard(x.split()[0])\n",
    "        pred = sum((1 if piece.color == chess.WHITE else -1) * self.values[piece.piece_type] for piece in board.piece_map().values())\n",
    "        return pred if pred else random.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f29664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y, y_pred):\n",
    "    \"\"\"\n",
    "    Returns MSE of evaluation scores and accuracy of sign of evaluation \n",
    "    scores (which indicate winning player).\n",
    "    \"\"\"\n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    accuracy = np.mean(np.sign(y) == np.sign(y_pred))\n",
    "    return mse, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb373829",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Baseline Test\n",
    "baseline = BaselineModel()\n",
    "\n",
    "y_pred = df_train['FEN'].apply(baseline.predict)\n",
    "mse, accuracy = eval(df_train['Evaluation'], y_pred)\n",
    "print(f'Baseline Train Error: {mse}.')\n",
    "print(f'Baseline Train Accuracy: {accuracy}.')\n",
    "\n",
    "y_pred = df_val['FEN'].apply(baseline.predict)\n",
    "mse, accuracy = eval(df_val['Evaluation'], y_pred)\n",
    "print(f'Baseline Validation Error: {mse}.')\n",
    "print(f'Baseline Validation Accuracy: {accuracy}.')\n",
    "\n",
    "y_pred = df_test['FEN'].apply(baseline.predict)\n",
    "mse, accuracy = eval(df_test['Evaluation'], y_pred)\n",
    "print(f'Baseline Test Error: {mse}.')\n",
    "print(f'Baseline Test Accuracy: {accuracy}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be954bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        DROPOUT_PROB = 0.5\n",
    "        INPUT_SIZE = 768\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.linear1 = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.linear2 = nn.Linear(INPUT_SIZE // 2, INPUT_SIZE // 4)\n",
    "        self.linear3 = nn.Linear(INPUT_SIZE // 4, 1)\n",
    "\n",
    "    def predict(self, x, device):\n",
    "        input = torch.as_tensor(fenToVec2D(x).values, dtype=torch.float32)\n",
    "        input = input.to(device)\n",
    "        input = F.relu(self.linear1(input))\n",
    "        input = self.dropout(input)\n",
    "        input = F.relu(self.linear2(input))\n",
    "        input = self.dropout(input)\n",
    "        output = self.linear3(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85edfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        DROPOUT_PROB = 0.5\n",
    "        INPUT_SIZE = 256\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.linear1 = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.linear2 = nn.Linear(INPUT_SIZE // 2, INPUT_SIZE // 4)\n",
    "        self.linear3 = nn.Linear(INPUT_SIZE // 4, 1)\n",
    "        self.conv1 = nn.Conv2d(in_channels = 12, out_channels = 64, kernel_size = 2, stride = (2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 2, stride = (2,2))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = INPUT_SIZE, kernel_size = 2, stride = (2,2))\n",
    "\n",
    "    def predict(self, x, device):\n",
    "        input = torch.as_tensor(fenToVec2D(x).values, dtype=torch.float32)\n",
    "        input = input.to(device)\n",
    "        input = input.reshape(-1, 12, 8, 8)\n",
    "        input = self.conv1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.conv3(input)\n",
    "        input = torch.flatten(input, start_dim=1)   \n",
    "        input = F.relu(self.linear1(input))\n",
    "        input = self.dropout(input)\n",
    "        input = F.relu(self.linear2(input))\n",
    "        input = self.dropout(input)\n",
    "        output = self.linear3(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5470997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def batches(dataset, sz=256):\n",
    "    return enumerate(dataset[i*sz:(i+1)*sz] for i in range(ceil(dataset.shape[0] / sz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test(model, device, dataset, flag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        truth = []\n",
    "        predictions = []\n",
    "        for step, batch in tqdm(batches(dataset), desc=f\"{flag} eval\"):\n",
    "            b_fens, b_labels = batch['FEN'], batch['Evaluation']\n",
    "            truth.extend(b_labels)\n",
    "            logits = model.predict(b_fens, device)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            predictions.extend(logits)\n",
    "        mse, accuracy = eval(np.array(truth).flatten(), np.array(predictions).flatten())\n",
    "    return mse, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eeb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train(modelType, trainset, valset, testset, lr, epochs):\n",
    "    print(f\"Beginning training with {epochs} epochs.\")\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    model = modelType()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr) #weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    train_mse, train_acc = test(model, device, trainset, 'train')\n",
    "    val_mse, val_acc = test(model, device, valset, 'val')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch number: {epoch}, train acc: {train_acc}, val acc: {val_acc}, train mse: {train_mse}, val mse: {val_mse}\")\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in tqdm(batches(trainset), desc='train'):\n",
    "            b_fens, b_labels = batch['FEN'], batch['Evaluation']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model.predict(b_fens, device)\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values).float()\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.mse_loss(logits.flatten(), b_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_mse, train_acc = test(model, device, trainset, 'train')\n",
    "        val_mse, val_acc = test(model, device, valset, 'val')\n",
    "        \n",
    "        scheduler.step(val_mse)\n",
    "    \n",
    "    test_mse, test_acc = test(model, device, testset, 'test')\n",
    "    print(f\"epoch number: {epochs}, train acc: {train_acc}, val acc: {val_acc}, test acc: {test_acc}, train mse: {train_mse}, val mse: {val_mse}, test mse: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e50ddc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 35 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train eval: 313it [00:23, 13.15it/s]\n",
      "val eval: 40it [00:03, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, train acc: 0.7395375, val acc: 0.7451, train mse: 81866.98278975082, val mse: 79583.29399572473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:25, 12.50it/s]\n",
      "train eval: 313it [00:25, 12.32it/s]\n",
      "val eval: 40it [00:03, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, train acc: 0.794175, val acc: 0.7904, train mse: 59896.675279498246, val mse: 61136.91077705865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:25, 12.28it/s]\n",
      "train eval: 313it [00:23, 13.16it/s]\n",
      "val eval: 40it [00:03, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, train acc: 0.84195, val acc: 0.8255, train mse: 43358.68626935491, val mse: 48652.539436427214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:25, 12.20it/s]\n",
      "train eval: 313it [00:23, 13.30it/s]\n",
      "val eval: 40it [00:03, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 3, train acc: 0.8643, val acc: 0.8465, train mse: 30365.641107256048, val mse: 39147.51908492858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.82it/s]\n",
      "train eval: 313it [00:24, 13.01it/s]\n",
      "val eval: 40it [00:03, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4, train acc: 0.8726875, val acc: 0.8492, train mse: 22418.347170698176, val mse: 34138.49982601687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:25, 12.31it/s]\n",
      "train eval: 313it [00:24, 12.75it/s]\n",
      "val eval: 40it [00:03, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 5, train acc: 0.8768, val acc: 0.8531, train mse: 17770.947442851328, val mse: 30866.144710520988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:25, 12.48it/s]\n",
      "train eval: 313it [00:23, 13.30it/s]\n",
      "val eval: 40it [00:03, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 6, train acc: 0.8788375, val acc: 0.8559, train mse: 14949.659515709769, val mse: 28852.5610929097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.70it/s]\n",
      "train eval: 313it [00:23, 13.49it/s]\n",
      "val eval: 40it [00:02, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 7, train acc: 0.8814375, val acc: 0.8542, train mse: 12924.593067839727, val mse: 27529.859629809933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.70it/s]\n",
      "train eval: 313it [00:22, 13.68it/s]\n",
      "val eval: 40it [00:02, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 8, train acc: 0.87975, val acc: 0.8564, train mse: 11733.489801323516, val mse: 26816.017598287293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.98it/s]\n",
      "train eval: 313it [00:23, 13.49it/s]\n",
      "val eval: 40it [00:02, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 9, train acc: 0.8848, val acc: 0.8587, train mse: 10540.178954902163, val mse: 25906.056548042096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.75it/s]\n",
      "train eval: 313it [00:23, 13.61it/s]\n",
      "val eval: 40it [00:03, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 10, train acc: 0.882875, val acc: 0.8569, train mse: 10162.933398420935, val mse: 25996.241959725143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.69it/s]\n",
      "train eval: 313it [00:23, 13.53it/s]\n",
      "val eval: 40it [00:02, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 11, train acc: 0.885875, val acc: 0.8598, train mse: 9341.117633225673, val mse: 25325.075506923466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.76it/s]\n",
      "train eval: 313it [00:23, 13.30it/s]\n",
      "val eval: 40it [00:02, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 12, train acc: 0.8902875, val acc: 0.8611, train mse: 8546.840225861164, val mse: 25211.16297878357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.92it/s]\n",
      "train eval: 313it [00:23, 13.21it/s]\n",
      "val eval: 40it [00:03, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 13, train acc: 0.89115, val acc: 0.8633, train mse: 8576.242361780493, val mse: 24918.26861705107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 313it [00:24, 12.92it/s]\n",
      "train eval: 313it [00:23, 13.47it/s]\n",
      "val eval: 40it [00:03, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 14, train acc: 0.8934875, val acc: 0.8643, train mse: 8023.8189542447735, val mse: 24871.365896293184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 44it [00:03, 13.07it/s]"
     ]
    }
   ],
   "source": [
    "### MLP Test\n",
    "train(MLPModel, df_train, df_val, df_test, 3e-3, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Test\n",
    "trained_model = train(CNNModel, df_train, df_val, df_test, 3e-4, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.svg\n",
    "\n",
    "def experimentation(model, examples):\n",
    "    for example in examples.iterrows():\n",
    "        board = chess.BaseBoard(example['FEN'])\n",
    "        chess.svg.board(board, squares=chess.SquareSet(chess.BB_DARK_SQUARES & chess.BB_FILE_B), size=350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
